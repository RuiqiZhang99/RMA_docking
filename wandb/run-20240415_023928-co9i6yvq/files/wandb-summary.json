{"train/entropy_loss": -6.800653600692749, "_timestamp": 1713174077.7702608, "train/policy_gradient_loss": -0.026186070716008203, "train/value_loss": 1.1193773746490479, "train/approx_kl": 0.043593354523181915, "train/clip_fraction": 0.17399999424815177, "train/loss": 0.4888312816619873, "train/std": 0.5679494738578796, "train/n_updates": 11400, "train/clip_range": 0.2, "_runtime": 109.5620768070221, "_step": 57000, "rewards/total_reward": 44.921045, "rollout/ep_len_mean": 24}